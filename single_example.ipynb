{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.6.0 (from -r requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/26/6b86448bda61c1ce463ad2c962641a933113f4496de16085df41217cdccc/torch-1.6.0-cp37-none-macosx_10_9_x86_64.whl (97.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 97.4MB 536kB/s ta 0:00:011  3% |█▎                              | 3.9MB 3.1MB/s eta 0:00:31    14% |████▋                           | 14.1MB 3.8MB/s eta 0:00:23    16% |█████▏                          | 15.8MB 7.6MB/s eta 0:00:11    22% |███████                         | 21.5MB 5.9MB/s eta 0:00:13    31% |██████████▏                     | 31.1MB 3.8MB/s eta 0:00:18\n",
      "\u001b[?25hCollecting torchvision==0.7.0 (from -r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/68/b82d188d09a40e681e8df5eeb91f71bb1facdc5c8a61a905350fa398a4a4/torchvision-0.7.0-cp37-cp37m-macosx_10_9_x86_64.whl (387kB)\n",
      "\u001b[K    100% |████████████████████████████████| 389kB 4.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorboardX==2.1 in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (2.1)\n",
      "Collecting transformers==3.4.0 (from -r requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl\n",
      "Requirement already satisfied: future in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from torch==1.6.0->-r requirements.txt (line 1)) (0.18.2)\n",
      "Requirement already satisfied: numpy in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from torch==1.6.0->-r requirements.txt (line 1)) (1.17.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from torchvision==0.7.0->-r requirements.txt (line 2)) (5.4.1)\n",
      "Requirement already satisfied: six in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from tensorboardX==2.1->-r requirements.txt (line 3)) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from tensorboardX==2.1->-r requirements.txt (line 3)) (3.12.1)\n",
      "Requirement already satisfied: requests in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from transformers==3.4.0->-r requirements.txt (line 4)) (2.22.0)\n",
      "Requirement already satisfied: filelock in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from transformers==3.4.0->-r requirements.txt (line 4)) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from transformers==3.4.0->-r requirements.txt (line 4)) (4.32.1)\n",
      "Collecting tokenizers==0.9.2 (from transformers==3.4.0->-r requirements.txt (line 4))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/6b/0b1bb8a176ea05e53ecce09441780af99e919b2f83626ac8a06ce8f5a349/tokenizers-0.9.2-cp37-cp37m-macosx_10_11_x86_64.whl (2.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.0MB 18.0MB/s ta 0:00:01   15% |████▉                           | 296kB 3.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sacremoses in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from transformers==3.4.0->-r requirements.txt (line 4)) (0.0.43)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from transformers==3.4.0->-r requirements.txt (line 4)) (2019.8.19)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from transformers==3.4.0->-r requirements.txt (line 4)) (0.1.91)\n",
      "Requirement already satisfied: packaging in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from transformers==3.4.0->-r requirements.txt (line 4)) (20.4)\n",
      "Requirement already satisfied: setuptools in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorboardX==2.1->-r requirements.txt (line 3)) (40.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from requests->transformers==3.4.0->-r requirements.txt (line 4)) (2018.11.29)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from requests->transformers==3.4.0->-r requirements.txt (line 4)) (2.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from requests->transformers==3.4.0->-r requirements.txt (line 4)) (1.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from requests->transformers==3.4.0->-r requirements.txt (line 4)) (3.0.4)\n",
      "Requirement already satisfied: click in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from sacremoses->transformers==3.4.0->-r requirements.txt (line 4)) (7.1.2)\n",
      "Requirement already satisfied: joblib in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from sacremoses->transformers==3.4.0->-r requirements.txt (line 4)) (0.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/haonanl5/miniconda3/lib/python3.7/site-packages (from packaging->transformers==3.4.0->-r requirements.txt (line 4)) (2.2.1)\n",
      "Installing collected packages: torch, torchvision, tokenizers, transformers\n",
      "  Found existing installation: torch 1.2.0\n",
      "    Uninstalling torch-1.2.0:\n",
      "      Successfully uninstalled torch-1.2.0\n",
      "  Found existing installation: tokenizers 0.8.1rc2\n",
      "    Uninstalling tokenizers-0.8.1rc2:\n",
      "      Successfully uninstalled tokenizers-0.8.1rc2\n",
      "  Found existing installation: transformers 3.3.1\n",
      "    Uninstalling transformers-3.3.1:\n",
      "      Successfully uninstalled transformers-3.3.1\n",
      "Successfully installed tokenizers-0.9.2 torch-1.6.0 torchvision-0.7.0 transformers-3.4.0\n",
      "\u001b[33mYou are using pip version 18.0, however version 20.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model\n",
    "\n",
    "To train a model you should specify the arguments, for example:\n",
    "\n",
    "```bash\n",
    "python run_metonymy_resolution.py \\\n",
    "--data_dir ../data \\\n",
    "--train_file conll_train.json \\\n",
    "--predict_file conll_test.json \\\n",
    "--output_dir ../output \\\n",
    "--do_train  \\\n",
    "--do_eval \\\n",
    "--do_mask\n",
    "```\n",
    "\n",
    "# You can also use our pretrained model\n",
    "\n",
    "Download from, https://drive.google.com/file/d/1PCXkEFyK5OALQbF_64J6jSGO0IUjbYuf/view?usp=sharing\n",
    "\n",
    "Unzip and put it to ``model_folder`` (you local path).\n",
    "\n",
    "This is a pretrained bert-base-uncased model, use ./data/conll_train.json."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained model from ``model_folder``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"./src\")\n",
    "from utils_metonymy import *\n",
    "\n",
    "model_class = BertForWordClassification\n",
    "tokenizer_class = BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = './output' # specify which dir the model been saved.\n",
    "\n",
    "model = model_class.from_pretrained(model_folder)\n",
    "tokenizer = tokenizer_class.from_pretrained(model_folder, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = {'sentence': ['SOCCER', '-', 'ROMANIA', 'BEAT', 'LITHUANIA', 'IN', 'UNDER-21', 'MATCH.'],\n",
    "           'pos': [2, 3]}\n",
    "\n",
    "inputs = convert_single_example_to_input(example, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model on the input example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target word:   ROMANIA\n",
      "Sentence:      SOCCER - ROMANIA BEAT LITHUANIA IN UNDER-21 MATCH.\n",
      "Prediction:    literal\n"
     ]
    }
   ],
   "source": [
    "model.zero_grad()\n",
    "model.eval()\n",
    "\n",
    "logits = model(**inputs)[0]\n",
    "\n",
    "\n",
    "preds = logits.detach().cpu().numpy()\n",
    "preds = np.argmax(preds, axis=1)\n",
    "\n",
    "label_map = {0:'literal',1:'metonymy'}\n",
    "\n",
    "print(f'Target word:   {\" \".join(example[\"sentence\"][example[\"pos\"][0]:example[\"pos\"][1]])}')\n",
    "print(f'Sentence:      {\" \".join(example[\"sentence\"])}')\n",
    "print(f'Prediction:    {label_map[preds[0]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
